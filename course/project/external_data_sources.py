from pyspark.sql import DataFrame
from pyspark.sql import SparkSession

"""
Working with external data sources
---------------------------------
    ✨ Integrating with external data stores (Hive, HBase, Cassandra, etc.)
    ✨ Reading and writing data from and to external systems
    ✨ Schema management and synchronization
    ✨ Hands-On: Practical examples and use cases
    
    
"""


def external_data_sources(spark: SparkSession):
    pass
